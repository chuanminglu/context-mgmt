#!/usr/bin/env python3
"""
ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå™¨
"""
import os
import sys
import json
from datetime import datetime
from pathlib import Path

# å¸¸é‡å®šä¹‰
NO_FEATURES_MSG = "- æš‚æ— åŠŸèƒ½ä¿¡æ¯"
NO_CONSTRAINTS_MSG = "- æš‚æ— çº¦æŸä¿¡æ¯"
NO_FILES_MSG = "- æš‚æ— è¯†åˆ«åˆ°é‡è¦æ–‡ä»¶"

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥project_detectoræ¨¡å—
try:
    from project_detector import ProjectDetector  # type: ignore
except ImportError as e:
    print(f"âŒ é”™è¯¯: æ— æ³•å¯¼å…¥project_detectoræ¨¡å—: {e}")
    print("ğŸ“ è¯·ç¡®ä¿project_detector.pyæ–‡ä»¶å­˜åœ¨äºåŒä¸€ç›®å½•ä¸‹")
    print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    print("   1. æ£€æŸ¥ .ai-context/tools/project_detector.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    print("   2. ç¡®ä¿æ–‡ä»¶å†…å®¹å®Œæ•´ä¸”è¯­æ³•æ­£ç¡®")
    print("   3. å¦‚æœæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·é‡æ–°åˆ›å»ºè¯¥æ–‡ä»¶")
    sys.exit(1)

class ContextGenerator:
    def __init__(self, project_root):
        self.project_root = Path(project_root).resolve()  # ç¡®ä¿æ˜¯ç»å¯¹è·¯å¾„
        self.ai_context_dir = self.project_root / ".ai-context"
        
        # è¯»å–æ‰«æé…ç½®
        self.scanning_config = self._load_scanning_config()
        
    def _load_scanning_config(self):
        """åŠ è½½æ‰«æé…ç½®"""
        # é»˜è®¤é…ç½®
        default_config = {
            "max_depth": 3,
            "include_hidden_dirs": False,
            "special_include_dirs": [".ai-context"],
            "exclude_dirs": ["__pycache__", "node_modules", ".git"],
            "important_extensions": [".py", ".js", ".md", ".json", ".yml", ".yaml", ".sql", ".db", ".html", ".css", ".tsx", ".jsx", ".ts"]
        }
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = self.ai_context_dir / "context-config.json"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    base_scanning_config = config.get('scanning', {})
                    
                    # åˆå¹¶é»˜è®¤é…ç½®
                    for key, value in default_config.items():
                        if key not in base_scanning_config:
                            base_scanning_config[key] = value
                    
                    # æ£€æµ‹é¡¹ç›®ç±»å‹å¹¶åº”ç”¨ç‰¹å®šé…ç½®
                    project_type = config.get('project', {}).get('type', 'general')
                    project_specific = base_scanning_config.get('project_specific', {})
                    
                    if project_type in project_specific:
                        specific_config = project_specific[project_type]
                        # åº”ç”¨é¡¹ç›®ç‰¹å®šé…ç½®
                        for key, value in specific_config.items():
                            if key != 'project_specific':  # é¿å…é€’å½’
                                base_scanning_config[key] = value
                    
                    return base_scanning_config
            except (json.JSONDecodeError, FileNotFoundError):
                pass
        
        return default_config
    
    def generate_context_summary(self):
        """ç”Ÿæˆç®€åŒ–çš„ä¸Šä¸‹æ–‡æ€»ç»“"""
        detector = ProjectDetector(str(self.project_root))
        proj_type, _ = detector.detect_project_type()  # ä½¿ç”¨ä¸‹åˆ’çº¿å¿½ç•¥æœªä½¿ç”¨çš„å˜é‡
        tech_stack = detector.get_tech_stack()
        
        # è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯
        project_info = self._read_project_config()
        
        summary = ["# é¡¹ç›®ä¸Šä¸‹æ–‡æ€»ç»“"]
        
        # åŸºæœ¬é¡¹ç›®ä¿¡æ¯
        summary.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        summary.append("")
        summary.append("## é¡¹ç›®ä¿¡æ¯")
        summary.append(f"- åç§°: {project_info.get('name', self.project_root.name)}")
        summary.append(f"- ç±»å‹: {project_info.get('type', proj_type)}")
        summary.append(f"- æŠ€æœ¯æ ˆ: {', '.join(project_info.get('tech_stack', tech_stack))}")
        summary.append(f"- è·¯å¾„: {self.project_root}")
        summary.append("")
        
        # æ ¸å¿ƒåŠŸèƒ½
        summary.append("## æ ¸å¿ƒåŠŸèƒ½")
        summary.append(self._get_core_features())
        
        # é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶
        summary.append("## é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶")
        summary.append(self._get_important_files())
        
        # æœ€è¿‘æ›´æ–°
        summary.append("## æœ€è¿‘æ›´æ–°")
        recent_files = self._get_recently_modified_files()
        summary.extend(self._format_recent_files(recent_files))
        
        # é¡¹ç›®çŠ¶æ€ï¼ˆé›†æˆæ‰‹åŠ¨çŠ¶æ€è®°å½•ï¼‰
        summary.append("")
        summary.append("## é¡¹ç›®ç®¡ç†çŠ¶æ€")
        project_status = self._get_project_status()
        summary.append(project_status)
        
        # æŠ€æœ¯çº¦æŸ
        summary.append("")
        summary.append("## æŠ€æœ¯çº¦æŸ")
        summary.append(self._get_technical_constraints())
        
        # å½“å‰å¼€å‘çŠ¶æ€
        summary.append("")
        summary.append("## å½“å‰å¼€å‘çŠ¶æ€")
        summary.append(self._get_development_status())
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„å­—ç¬¦ä¸²
        summary_md = "\n".join(summary)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        cache_file = self.ai_context_dir / "cache" / "latest-context.md"
        cache_file.parent.mkdir(exist_ok=True)
        with open(cache_file, 'w', encoding='utf-8') as f:
            f.write(summary_md)
        
        return summary_md
    
    def _read_project_config(self):
        """è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯"""
        config_file = self.ai_context_dir / "context-config.json"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config.get('project', {})
            except (json.JSONDecodeError, FileNotFoundError):
                pass
        return {}
    
    def _get_core_features(self):
        """è·å–æ ¸å¿ƒåŠŸèƒ½ä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_FEATURES_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æ ¸å¿ƒåŠŸèƒ½", NO_FEATURES_MSG)
        except FileNotFoundError:
            return NO_FEATURES_MSG
    
    def _extract_section_content(self, content, section_header, default_message):
        """æå–æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        if section_header not in content:
            return default_message
        
        lines = content.split('\n')
        features = []
        in_section = False
        
        for line in lines:
            if line.startswith(section_header):
                in_section = True
            elif in_section and line.startswith("##"):
                break
            elif in_section and line.strip():
                features.append(line.strip())
        
        return '\n'.join(features[:5]) if features else default_message
    
    def _get_technical_constraints(self):
        """è·å–æŠ€æœ¯çº¦æŸä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_CONSTRAINTS_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æŠ€æœ¯çº¦æŸ", NO_CONSTRAINTS_MSG)
        except FileNotFoundError:
            return NO_CONSTRAINTS_MSG
    
    def _get_important_files(self):
        """è·å–é‡è¦æ–‡ä»¶åˆ—è¡¨"""
        important_files = []
        self._scan_directory(self.project_root, important_files)
        return "\n".join(important_files[:50]) if important_files else NO_FILES_MSG  # å¢åŠ åˆ°50ä¸ªæ–‡ä»¶
    
    def _scan_directory(self, path, important_files, prefix="", current_depth=0):
        """é€’å½’æ‰«æç›®å½•ç»“æ„ï¼ˆåŸºäºé…ç½®ï¼‰"""
        max_depth = self.scanning_config.get('max_depth', 3)
        if current_depth >= max_depth:
            return
        
        try:
            items = list(path.iterdir())
            dirs = [item for item in items if item.is_dir() and self._is_important_dir(item)]
            files = [item for item in items if item.is_file() and self._is_important_file(item)]
            
            # æ·»åŠ é‡è¦ç›®å½•
            for directory in sorted(dirs):
                try:
                    important_files.append(f"{prefix}- ğŸ“ {directory.name}/")
                    self._scan_directory(directory, important_files, prefix + "  ", current_depth + 1)
                except UnicodeError:
                    # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬ç‰ˆæœ¬
                    important_files.append(f"{prefix}- [DIR] {directory.name}/")
                    self._scan_directory(directory, important_files, prefix + "  ", current_depth + 1)
            
            # æ·»åŠ é‡è¦æ–‡ä»¶
            for file_path in sorted(files):
                try:
                    important_files.append(f"{prefix}- ğŸ“„ {file_path.name}")
                except UnicodeError:
                    # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬ç‰ˆæœ¬
                    important_files.append(f"{prefix}- [FILE] {file_path.name}")
                        
        except PermissionError:
            pass
        except Exception as e:
            # æ·»åŠ é€šç”¨å¼‚å¸¸å¤„ç†ä»¥è¯Šæ–­é—®é¢˜
            important_files.append(f"{prefix}- [ERROR] æ‰«æ {path.name} æ—¶å‡ºé”™: {e}")
    
    def _is_important_dir(self, directory):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦ç›®å½•ï¼ˆåŸºäºé…ç½®ï¼‰"""
        include_hidden = self.scanning_config.get('include_hidden_dirs', False)
        special_include = self.scanning_config.get('special_include_dirs', [])
        exclude_dirs = self.scanning_config.get('exclude_dirs', [])
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if directory.name in exclude_dirs:
            return False
        
        # æ£€æŸ¥ç‰¹æ®ŠåŒ…å«ç›®å½•
        if directory.name in special_include:
            return True
        
        # æ£€æŸ¥éšè—ç›®å½•
        if directory.name.startswith('.'):
            return include_hidden
        
        return True
    
    def _is_important_file(self, file_path):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦æ–‡ä»¶ï¼ˆåŸºäºé…ç½®ï¼‰"""
        important_extensions = self.scanning_config.get('important_extensions', [])
        
        # è·³è¿‡éšè—æ–‡ä»¶ï¼ˆé™¤éé…ç½®å…è®¸ï¼‰
        if file_path.name.startswith('.'):
            return False
            
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        return file_path.suffix.lower() in important_extensions
    
    def _get_recent_changes(self):
        """è·å–æœ€è¿‘å˜æ›´ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        changes = []
        
        try:
            # è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
            recent_files = self._get_recently_modified_files()
            if recent_files:
                changes.extend(self._format_recent_files(recent_files))
            
            # å°è¯•è·å–Gitå†å²
            git_history = self._get_git_history()
            if git_history:
                changes.append("\n## Gitæäº¤å†å²:")
                changes.extend(git_history)
            
            if not changes:
                changes.append("- æœªå‘ç°æœ€è¿‘æ›´æ”¹")
                
        except Exception as e:
            changes.append(f"- è·å–å˜æ›´ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return "\n".join(changes)
    
    def _get_recently_modified_files(self):
        """è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆåŸºäºé…ç½®ï¼‰"""
        recent_files = []
        
        # ä»é…ç½®è¯»å–å‚æ•°
        recent_config = self.scanning_config
        if 'recent_files' in self.scanning_config:
            # å¦‚æœæœ‰ä¸“é—¨çš„ recent_files é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨
            config_file = self.ai_context_dir / "context-config.json"
            if config_file.exists():
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        full_config = json.load(f)
                        recent_config = full_config.get('recent_files', self.scanning_config)
                except:
                    pass
        
        days_threshold = recent_config.get('days_threshold', 7)
        max_depth = recent_config.get('max_depth', 3)
        cutoff_time = datetime.now().timestamp() - (days_threshold * 24 * 3600)
        
        def check_files(path, current_depth=0):
            if current_depth >= max_depth:
                return
                
            try:
                for item in path.iterdir():
                    # ä½¿ç”¨é…ç½®åŒ–çš„ç›®å½•è¿‡æ»¤é€»è¾‘
                    if item.is_dir():
                        if self._is_important_dir(item):
                            check_files(item, current_depth + 1)
                    elif item.is_file() and item.stat().st_mtime > cutoff_time:
                        # ä½¿ç”¨é…ç½®åŒ–çš„æ–‡ä»¶è¿‡æ»¤é€»è¾‘
                        if self._is_important_file(item) or not item.name.startswith('.'):
                            rel_path = item.relative_to(self.project_root)
                            recent_files.append((str(rel_path), item.stat().st_mtime))
            except PermissionError:
                pass
        
        check_files(self.project_root)
        return sorted(recent_files, key=lambda x: x[1], reverse=True)
    
    def _format_recent_files(self, recent_files):
        """æ ¼å¼åŒ–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨"""
        changes = ["## æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶:"]
        for file_path, mtime in recent_files[:10]:
            mod_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M")
            changes.append(f"- {file_path} ({mod_time})")
        return changes
    
    def _get_git_history(self):
        """è·å–Gitæäº¤å†å²"""
        try:
            import subprocess
            result = subprocess.run(
                ["git", "log", "--oneline", "-5"],
                capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0 and result.stdout.strip():
                return [f"- {line}" for line in result.stdout.strip().split('\n')]
        except Exception:
            pass
        return None
    
    def _get_development_status(self):
        """è·å–å½“å‰å¼€å‘çŠ¶æ€"""
        status_info = []
        
        # åŠ¨æ€æ£€æµ‹é¡¹ç›®ç±»å‹å¹¶æä¾›ç›¸åº”çš„çŠ¶æ€æ£€æŸ¥
        detector = ProjectDetector(str(self.project_root))
        proj_type, confidence = detector.detect_project_type()
        
        if proj_type == "context-management-system":
            # ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿçš„ç‰¹å®šçŠ¶æ€æ£€æŸ¥
            
            # æ£€æŸ¥æ ¸å¿ƒå·¥å…·è„šæœ¬
            tools_dir = self.project_root / ".ai-context" / "tools"
            if tools_dir.exists():
                tool_files = list(tools_dir.glob("*.py"))
                tool_files = [f for f in tool_files if f.name != "__init__.py"]
                if tool_files:
                    status_info.append(f"âœ… æ ¸å¿ƒå·¥å…·è„šæœ¬ ({len(tool_files)} ä¸ªå·¥å…·)")
                else:
                    status_info.append("â³ æ ¸å¿ƒå·¥å…·è„šæœ¬æœªå®Œæˆ")
            else:
                status_info.append("â³ æ ¸å¿ƒå·¥å…·è„šæœ¬æœªå¼€å§‹")
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            config_file = self.project_root / ".ai-context" / "context-config.json"
            if config_file.exists():
                status_info.append("âœ… é…ç½®ç³»ç»Ÿå·²å®Œæˆ")
            else:
                status_info.append("â³ é…ç½®ç³»ç»Ÿæœªå®Œæˆ")
            
            # æ£€æŸ¥VS Codeé›†æˆ
            vscode_dir = self.project_root / ".vscode"
            if vscode_dir.exists():
                tasks_file = vscode_dir / "tasks.json"
                if tasks_file.exists():
                    status_info.append("âœ… VS Codeä»»åŠ¡é›†æˆå®Œæˆ")
                else:
                    status_info.append("â³ VS Codeä»»åŠ¡é›†æˆæœªå®Œæˆ")
            else:
                status_info.append("â³ VS Codeé›†æˆæœªå¼€å§‹")
            
            # æ£€æŸ¥æ¨¡æ¿ç³»ç»Ÿ
            templates_dir = self.project_root / ".ai-context" / "templates"
            if templates_dir.exists() and list(templates_dir.glob("*.md")):
                status_info.append("âœ… æ¨¡æ¿ç³»ç»Ÿå·²å®Œæˆ")
            else:
                status_info.append("â³ æ¨¡æ¿ç³»ç»Ÿæœªå®Œæˆ")
            
            # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
            cache_dir = self.project_root / ".ai-context" / "cache"
            if cache_dir.exists() and list(cache_dir.glob("*.md")):
                status_info.append("âœ… ç¼“å­˜ç³»ç»Ÿæ­£å¸¸è¿è¡Œ")
            else:
                status_info.append("â³ ç¼“å­˜ç³»ç»Ÿæœªå¯ç”¨")
            
            # æ£€æŸ¥å¿«é€Ÿéƒ¨ç½²è„šæœ¬
            deploy_script = self.project_root / "deploy-ai-context.py"
            if deploy_script.exists():
                status_info.append("âœ… å¿«é€Ÿéƒ¨ç½²è„šæœ¬å®Œæˆ")
            else:
                status_info.append("â³ å¿«é€Ÿéƒ¨ç½²è„šæœ¬æœªå®Œæˆ")
                
        else:
            # ä¼ ç»Ÿé¡¹ç›®ç»“æ„çš„æ£€æŸ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            
            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            db_files = list(self.project_root.glob("**/*.db"))
            if db_files:
                status_info.append(f"âœ… æ•°æ®åº“å·²åˆ›å»º ({len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶)")
            else:
                status_info.append("â³ æ•°æ®åº“æœªåˆ›å»º")
            
            # æ£€æŸ¥åç«¯ä»£ç 
            backend_files = list((self.project_root / "backend").glob("**/*.py")) if (self.project_root / "backend").exists() else []
            if backend_files:
                status_info.append(f"ğŸ”§ åç«¯å¼€å‘ä¸­ ({len(backend_files)} ä¸ªPythonæ–‡ä»¶)")
            else:
                status_info.append("â³ åç«¯ä»£ç æœªå¼€å§‹")
            
            # æ£€æŸ¥å‰ç«¯ä»£ç 
            frontend_files = []
            if (self.project_root / "frontend").exists():
                frontend_files.extend(list((self.project_root / "frontend").glob("**/*.html")))
                frontend_files.extend(list((self.project_root / "frontend").glob("**/*.js")))
                frontend_files.extend(list((self.project_root / "frontend").glob("**/*.css")))
            
            if frontend_files:
                status_info.append(f"ğŸ¨ å‰ç«¯å¼€å‘ä¸­ ({len(frontend_files)} ä¸ªå‰ç«¯æ–‡ä»¶)")
            else:
                status_info.append("â³ å‰ç«¯ä»£ç æœªå¼€å§‹")
            
            # æ£€æŸ¥æµ‹è¯•ä»£ç 
            test_files = list((self.project_root / "tests").glob("**/*.py")) if (self.project_root / "tests").exists() else []
            if test_files:
                status_info.append(f"ğŸ§ª æµ‹è¯•ä»£ç  ({len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶)")
            else:
                status_info.append("â³ æµ‹è¯•ä»£ç æœªç¼–å†™")
        
        # é€šç”¨æ–‡æ¡£æ£€æŸ¥
        doc_files = list(self.project_root.glob("**/*.md"))
        doc_count = len([f for f in doc_files if ".ai-context" not in str(f)])
        if doc_count > 0:
            status_info.append(f"ğŸ“š é¡¹ç›®æ–‡æ¡£ ({doc_count} ä¸ªæ–‡æ¡£æ–‡ä»¶)")
        
        return "\n".join([f"- {info}" for info in status_info]) or "- é¡¹ç›®åˆšå¼€å§‹"
    
    def _get_project_status(self):
        """è¯»å–æœ€æ–°çš„é¡¹ç›®çŠ¶æ€ä¿¡æ¯"""
        status_file = self.project_root / '.ai-context' / 'status' / 'latest-status.md'
        
        if not status_file.exists():
            return "æš‚æ— é¡¹ç›®çŠ¶æ€è®°å½•"
            
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å…³é”®ä¿¡æ¯
            lines = content.split('\n')
            status_summary = []
            current_section = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('## å®Œæˆçš„å·¥ä½œ'):
                    current_section = 'completed'
                elif line.startswith('## è¿›è¡Œä¸­çš„ä»»åŠ¡'):
                    current_section = 'ongoing'
                elif line.startswith('## å¾…å¤„ç†é—®é¢˜'):
                    current_section = 'issues'
                elif line.startswith('## ä¸‹ä¸€æ­¥è®¡åˆ’'):
                    current_section = 'next'
                elif line.startswith('## é‡è¦è¯´æ˜'):
                    current_section = 'notes'
                elif line.startswith('- [x]') and current_section == 'completed':
                    status_summary.append(f"âœ… {line[6:].strip()}")
                elif line.startswith('- [ ]') and current_section == 'ongoing':
                    status_summary.append(f"ğŸ”„ {line[6:].strip()}")
                elif line.startswith('1.') and current_section == 'issues':
                    status_summary.append(f"â— {line[3:].strip()}")
                    
            return '\n'.join(status_summary[:8])  # é™åˆ¶æ˜¾ç¤ºæ¡ç›®
            
        except Exception as e:
            return f"è¯»å–é¡¹ç›®çŠ¶æ€æ—¶å‡ºé”™: {e}"

if __name__ == "__main__":
    generator = ContextGenerator(".")
    summary = generator.generate_context_summary()
    
    # å¤„ç† Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
    try:
        print(summary)
    except UnicodeEncodeError:
        # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œæ›¿æ¢æœ‰é—®é¢˜çš„å­—ç¬¦
        safe_summary = summary.replace('ğŸ“', '[DIR]').replace('ğŸ“„', '[FILE]')
        print(safe_summary)
