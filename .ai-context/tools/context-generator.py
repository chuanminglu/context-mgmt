#!/usr/bin/env python3
"""
ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå™¨
"""
import os
import sys
import json
from datetime import datetime
from pathlib import Path

# å¸¸é‡å®šä¹‰
NO_FEATURES_MSG = "- æš‚æ— åŠŸèƒ½ä¿¡æ¯"
NO_CONSTRAINTS_MSG = "- æš‚æ— çº¦æŸä¿¡æ¯"
NO_FILES_MSG = "- æš‚æ— è¯†åˆ«åˆ°é‡è¦æ–‡ä»¶"

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥project_detectoræ¨¡å—
try:
    from project_detector import ProjectDetector  # type: ignore
except ImportError as e:
    print(f"âŒ é”™è¯¯: æ— æ³•å¯¼å…¥project_detectoræ¨¡å—: {e}")
    print("ğŸ“ è¯·ç¡®ä¿project_detector.pyæ–‡ä»¶å­˜åœ¨äºåŒä¸€ç›®å½•ä¸‹")
    print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    print("   1. æ£€æŸ¥ .ai-context/tools/project_detector.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    print("   2. ç¡®ä¿æ–‡ä»¶å†…å®¹å®Œæ•´ä¸”è¯­æ³•æ­£ç¡®")
    print("   3. å¦‚æœæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·é‡æ–°åˆ›å»ºè¯¥æ–‡ä»¶")
    sys.exit(1)

class ContextGenerator:
    def __init__(self, project_root):
        self.project_root = Path(project_root).resolve()  # ç¡®ä¿æ˜¯ç»å¯¹è·¯å¾„
        self.ai_context_dir = self.project_root / ".ai-context"
        
    def generate_context_summary(self):
        """ç”Ÿæˆç®€åŒ–çš„ä¸Šä¸‹æ–‡æ€»ç»“"""
        detector = ProjectDetector(self.project_root)
        proj_type, _ = detector.detect_project_type()  # ä½¿ç”¨ä¸‹åˆ’çº¿å¿½ç•¥æœªä½¿ç”¨çš„å˜é‡
        tech_stack = detector.get_tech_stack()
        
        # è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯
        project_info = self._read_project_config()
        
        summary = ["# é¡¹ç›®ä¸Šä¸‹æ–‡æ€»ç»“"]
        
        # åŸºæœ¬é¡¹ç›®ä¿¡æ¯
        summary.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        summary.append("")
        summary.append("## é¡¹ç›®ä¿¡æ¯")
        summary.append(f"- åç§°: {project_info.get('name', self.project_root.name)}")
        summary.append(f"- ç±»å‹: {project_info.get('type', proj_type)}")
        summary.append(f"- æŠ€æœ¯æ ˆ: {', '.join(project_info.get('tech_stack', tech_stack))}")
        summary.append(f"- è·¯å¾„: {self.project_root}")
        summary.append("")
        
        # æ ¸å¿ƒåŠŸèƒ½
        summary.append("## æ ¸å¿ƒåŠŸèƒ½")
        summary.append(self._get_core_features())
        
        # é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶
        summary.append("## é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶")
        summary.append(self._get_important_files())
        
        # æœ€è¿‘æ›´æ–°
        summary.append("## æœ€è¿‘æ›´æ–°")
        recent_files = self._get_recently_modified_files()
        summary.extend(self._format_recent_files(recent_files))
        
        # é¡¹ç›®çŠ¶æ€ï¼ˆé›†æˆæ‰‹åŠ¨çŠ¶æ€è®°å½•ï¼‰
        summary.append("")
        summary.append("## é¡¹ç›®ç®¡ç†çŠ¶æ€")
        project_status = self._get_project_status()
        summary.append(project_status)
        
        # æŠ€æœ¯çº¦æŸ
        summary.append("")
        summary.append("## æŠ€æœ¯çº¦æŸ")
        summary.append(self._get_technical_constraints())
        
        # å½“å‰å¼€å‘çŠ¶æ€
        summary.append("")
        summary.append("## å½“å‰å¼€å‘çŠ¶æ€")
        summary.append(self._get_development_status())
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„å­—ç¬¦ä¸²
        summary_md = "\n".join(summary)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        cache_file = self.ai_context_dir / "cache" / "latest-context.md"
        cache_file.parent.mkdir(exist_ok=True)
        with open(cache_file, 'w', encoding='utf-8') as f:
            f.write(summary_md)
        
        return summary_md
    
    def _read_project_config(self):
        """è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯"""
        config_file = self.ai_context_dir / "context-config.json"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config.get('project', {})
            except (json.JSONDecodeError, FileNotFoundError):
                pass
        return {}
    
    def _get_core_features(self):
        """è·å–æ ¸å¿ƒåŠŸèƒ½ä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_FEATURES_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æ ¸å¿ƒåŠŸèƒ½", NO_FEATURES_MSG)
        except FileNotFoundError:
            return NO_FEATURES_MSG
    
    def _extract_section_content(self, content, section_header, default_message):
        """æå–æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        if section_header not in content:
            return default_message
        
        lines = content.split('\n')
        features = []
        in_section = False
        
        for line in lines:
            if line.startswith(section_header):
                in_section = True
            elif in_section and line.startswith("##"):
                break
            elif in_section and line.strip():
                features.append(line.strip())
        
        return '\n'.join(features[:5]) if features else default_message
    
    def _get_technical_constraints(self):
        """è·å–æŠ€æœ¯çº¦æŸä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_CONSTRAINTS_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æŠ€æœ¯çº¦æŸ", NO_CONSTRAINTS_MSG)
        except FileNotFoundError:
            return NO_CONSTRAINTS_MSG
    
    def _get_important_files(self):
        """è·å–é‡è¦æ–‡ä»¶åˆ—è¡¨"""
        important_files = []
        self._scan_directory(self.project_root, important_files)
        return "\n".join(important_files[:25]) if important_files else NO_FILES_MSG
    
    def _scan_directory(self, path, important_files, prefix="", max_depth=2, current_depth=0):
        """é€’å½’æ‰«æç›®å½•ç»“æ„"""
        if current_depth >= max_depth:
            return
        
        try:
            items = list(path.iterdir())
            dirs = [item for item in items if item.is_dir() and self._is_important_dir(item)]
            files = [item for item in items if item.is_file() and self._is_important_file(item)]
            
            # æ·»åŠ é‡è¦ç›®å½•
            for directory in sorted(dirs):
                important_files.append(f"{prefix}- ğŸ“ {directory.name}/")
                self._scan_directory(directory, important_files, prefix + "  ", max_depth, current_depth + 1)
            
            # æ·»åŠ é‡è¦æ–‡ä»¶
            for file_path in sorted(files):
                important_files.append(f"{prefix}- ğŸ“„ {file_path.name}")
                        
        except PermissionError:
            pass
    
    def _is_important_dir(self, directory):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦ç›®å½•"""
        return (not directory.name.startswith('.') and 
                directory.name not in ['__pycache__', 'node_modules', '.git'])
    
    def _is_important_file(self, file_path):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦æ–‡ä»¶"""
        return (not file_path.name.startswith('.') and 
                file_path.suffix in ['.py', '.js', '.md', '.json', '.yml', '.sql', '.db'])
    
    def _get_recent_changes(self):
        """è·å–æœ€è¿‘å˜æ›´ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        changes = []
        
        try:
            # è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
            recent_files = self._get_recently_modified_files()
            if recent_files:
                changes.extend(self._format_recent_files(recent_files))
            
            # å°è¯•è·å–Gitå†å²
            git_history = self._get_git_history()
            if git_history:
                changes.append("\n## Gitæäº¤å†å²:")
                changes.extend(git_history)
            
            if not changes:
                changes.append("- æœªå‘ç°æœ€è¿‘æ›´æ”¹")
                
        except Exception as e:
            changes.append(f"- è·å–å˜æ›´ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return "\n".join(changes)
    
    def _get_recently_modified_files(self):
        """è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨"""
        recent_files = []
        cutoff_time = datetime.now().timestamp() - (7 * 24 * 3600)  # 7å¤©å†…
        
        def check_files(path, max_depth=2, current_depth=0):
            if current_depth >= max_depth:
                return
                
            try:
                for item in path.iterdir():
                    if item.name.startswith('.'):
                        continue
                        
                    if item.is_file() and item.stat().st_mtime > cutoff_time:
                        rel_path = item.relative_to(self.project_root)
                        recent_files.append((str(rel_path), item.stat().st_mtime))
                    elif item.is_dir() and item.name not in ['__pycache__', 'node_modules']:
                        check_files(item, max_depth, current_depth + 1)
            except PermissionError:
                pass
        
        check_files(self.project_root)
        return sorted(recent_files, key=lambda x: x[1], reverse=True)
    
    def _format_recent_files(self, recent_files):
        """æ ¼å¼åŒ–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨"""
        changes = ["## æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶:"]
        for file_path, mtime in recent_files[:10]:
            mod_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M")
            changes.append(f"- {file_path} ({mod_time})")
        return changes
    
    def _get_git_history(self):
        """è·å–Gitæäº¤å†å²"""
        try:
            import subprocess
            result = subprocess.run(
                ["git", "log", "--oneline", "-5"],
                capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0 and result.stdout.strip():
                return [f"- {line}" for line in result.stdout.strip().split('\n')]
        except Exception:
            pass
        return None
    
    def _get_development_status(self):
        """è·å–å½“å‰å¼€å‘çŠ¶æ€"""
        status_info = []
        
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        db_files = list(self.project_root.glob("**/*.db"))
        if db_files:
            status_info.append(f"âœ… æ•°æ®åº“å·²åˆ›å»º ({len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶)")
        else:
            status_info.append("â³ æ•°æ®åº“æœªåˆ›å»º")
        
        # æ£€æŸ¥åç«¯ä»£ç 
        backend_files = list((self.project_root / "backend").glob("**/*.py")) if (self.project_root / "backend").exists() else []
        if backend_files:
            status_info.append(f"ğŸ”§ åç«¯å¼€å‘ä¸­ ({len(backend_files)} ä¸ªPythonæ–‡ä»¶)")
        else:
            status_info.append("â³ åç«¯ä»£ç æœªå¼€å§‹")
        
        # æ£€æŸ¥å‰ç«¯ä»£ç 
        frontend_files = []
        if (self.project_root / "frontend").exists():
            frontend_files.extend(list((self.project_root / "frontend").glob("**/*.html")))
            frontend_files.extend(list((self.project_root / "frontend").glob("**/*.js")))
            frontend_files.extend(list((self.project_root / "frontend").glob("**/*.css")))
        
        if frontend_files:
            status_info.append(f"ğŸ¨ å‰ç«¯å¼€å‘ä¸­ ({len(frontend_files)} ä¸ªå‰ç«¯æ–‡ä»¶)")
        else:
            status_info.append("â³ å‰ç«¯ä»£ç æœªå¼€å§‹")
        
        # æ£€æŸ¥æµ‹è¯•ä»£ç 
        test_files = list((self.project_root / "tests").glob("**/*.py")) if (self.project_root / "tests").exists() else []
        if test_files:
            status_info.append(f"ğŸ§ª æµ‹è¯•ä»£ç  ({len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶)")
        else:
            status_info.append("â³ æµ‹è¯•ä»£ç æœªç¼–å†™")
        
        # æ£€æŸ¥æ–‡æ¡£
        doc_files = list(self.project_root.glob("**/*.md"))
        doc_count = len([f for f in doc_files if ".ai-context" not in str(f)])
        if doc_count > 0:
            status_info.append(f"ğŸ“š é¡¹ç›®æ–‡æ¡£ ({doc_count} ä¸ªæ–‡æ¡£æ–‡ä»¶)")
        
        return "\n".join([f"- {info}" for info in status_info]) or "- é¡¹ç›®åˆšå¼€å§‹"
    
    def _get_project_status(self):
        """è¯»å–æœ€æ–°çš„é¡¹ç›®çŠ¶æ€ä¿¡æ¯"""
        status_file = self.project_root / '.ai-context' / 'status' / 'latest-status.md'
        
        if not status_file.exists():
            return "æš‚æ— é¡¹ç›®çŠ¶æ€è®°å½•"
            
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å…³é”®ä¿¡æ¯
            lines = content.split('\n')
            status_summary = []
            current_section = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('## å®Œæˆçš„å·¥ä½œ'):
                    current_section = 'completed'
                elif line.startswith('## è¿›è¡Œä¸­çš„ä»»åŠ¡'):
                    current_section = 'ongoing'
                elif line.startswith('## å¾…å¤„ç†é—®é¢˜'):
                    current_section = 'issues'
                elif line.startswith('## ä¸‹ä¸€æ­¥è®¡åˆ’'):
                    current_section = 'next'
                elif line.startswith('## é‡è¦è¯´æ˜'):
                    current_section = 'notes'
                elif line.startswith('- [x]') and current_section == 'completed':
                    status_summary.append(f"âœ… {line[6:].strip()}")
                elif line.startswith('- [ ]') and current_section == 'ongoing':
                    status_summary.append(f"ğŸ”„ {line[6:].strip()}")
                elif line.startswith('1.') and current_section == 'issues':
                    status_summary.append(f"â— {line[3:].strip()}")
                    
            return '\n'.join(status_summary[:8])  # é™åˆ¶æ˜¾ç¤ºæ¡ç›®
            
        except Exception as e:
            return f"è¯»å–é¡¹ç›®çŠ¶æ€æ—¶å‡ºé”™: {e}"

if __name__ == "__main__":
    generator = ContextGenerator(".")
    summary = generator.generate_context_summary()
    print(summary)
