#!/usr/bin/env python3
"""
ä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆå™¨
"""
import os
import sys
import json
from datetime import datetime
from pathlib import Path

# å¸¸é‡å®šä¹‰
NO_FEATURES_MSG = "- æš‚æ— åŠŸèƒ½ä¿¡æ¯"
NO_CONSTRAINTS_MSG = "- æš‚æ— çº¦æŸä¿¡æ¯"
NO_FILES_MSG = "- æš‚æ— è¯†åˆ«åˆ°é‡è¦æ–‡ä»¶"
AI_CONTEXT_DIR = ".ai-context"
CONFIG_FILE_NAME = "context-config.json"

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥project_detectoræ¨¡å—
try:
    from project_detector import ProjectDetector  # type: ignore
except ImportError as e:
    print(f"âŒ é”™è¯¯: æ— æ³•å¯¼å…¥project_detectoræ¨¡å—: {e}")
    print("ğŸ“ è¯·ç¡®ä¿project_detector.pyæ–‡ä»¶å­˜åœ¨äºåŒä¸€ç›®å½•ä¸‹")
    print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    print("   1. æ£€æŸ¥ .ai-context/tools/project_detector.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    print("   2. ç¡®ä¿æ–‡ä»¶å†…å®¹å®Œæ•´ä¸”è¯­æ³•æ­£ç¡®")
    print("   3. å¦‚æœæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·é‡æ–°åˆ›å»ºè¯¥æ–‡ä»¶")
    sys.exit(1)

class ContextGenerator:
    def __init__(self, project_root):
        self.project_root = Path(project_root).resolve()  # ç¡®ä¿æ˜¯ç»å¯¹è·¯å¾„
        self.ai_context_dir = self.project_root / AI_CONTEXT_DIR
        
        # è¯»å–æ‰«æé…ç½®
        self.scanning_config = self._load_scanning_config()
        
    def _load_scanning_config(self):
        """åŠ è½½æ‰«æé…ç½®"""
        default_config = self._get_default_scanning_config()
        
        config_file = self.ai_context_dir / CONFIG_FILE_NAME
        if not config_file.exists():
            return default_config
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return self._merge_scanning_config(default_config, config)
        except (json.JSONDecodeError, FileNotFoundError):
            return default_config
    
    def _get_default_scanning_config(self):
        """è·å–é»˜è®¤æ‰«æé…ç½®"""
        return {
            "max_depth": 3,
            "include_hidden_dirs": False,
            "special_include_dirs": [AI_CONTEXT_DIR],
            "exclude_dirs": ["__pycache__", "node_modules", ".git"],
            "important_extensions": [".py", ".js", ".md", ".json", ".yml", ".yaml", ".sql", ".db", ".html", ".css", ".tsx", ".jsx", ".ts"]
        }
    
    def _merge_scanning_config(self, default_config, config):
        """åˆå¹¶æ‰«æé…ç½®"""
        base_scanning_config = config.get('scanning', {})
        
        # åˆå¹¶é»˜è®¤é…ç½®
        for key, value in default_config.items():
            if key not in base_scanning_config:
                base_scanning_config[key] = value
        
        # åº”ç”¨é¡¹ç›®ç‰¹å®šé…ç½®
        project_type = config.get('project', {}).get('type', 'general')
        project_specific = base_scanning_config.get('project_specific', {})
        
        if project_type in project_specific:
            specific_config = project_specific[project_type]
            for key, value in specific_config.items():
                if key != 'project_specific':  # é¿å…é€’å½’
                    base_scanning_config[key] = value
        
        return base_scanning_config
    
    def generate_context_summary(self):
        """ç”Ÿæˆç®€åŒ–çš„ä¸Šä¸‹æ–‡æ€»ç»“"""
        detector = ProjectDetector(str(self.project_root))
        proj_type, _ = detector.detect_project_type()  # ä½¿ç”¨ä¸‹åˆ’çº¿å¿½ç•¥æœªä½¿ç”¨çš„å˜é‡
        tech_stack = detector.get_tech_stack()
        
        # è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯
        project_info = self._read_project_config()
        
        summary = ["# é¡¹ç›®ä¸Šä¸‹æ–‡æ€»ç»“"]
        
        # åŸºæœ¬é¡¹ç›®ä¿¡æ¯
        summary.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        summary.append("")
        summary.append("## é¡¹ç›®ä¿¡æ¯")
        summary.append(f"- åç§°: {project_info.get('name', self.project_root.name)}")
        summary.append(f"- ç±»å‹: {project_info.get('type', proj_type)}")
        summary.append(f"- æŠ€æœ¯æ ˆ: {', '.join(project_info.get('tech_stack', tech_stack))}")
        summary.append(f"- è·¯å¾„: {self.project_root}")
        summary.append("")
        
        # æ ¸å¿ƒåŠŸèƒ½
        summary.append("## æ ¸å¿ƒåŠŸèƒ½")
        summary.append(self._get_core_features())
        
        # é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶
        summary.append("## é¡¹ç›®ç»“æ„ä¸é‡è¦æ–‡ä»¶")
        summary.append(self._get_important_files())
        
        # æœ€è¿‘æ›´æ–°
        summary.append("## æœ€è¿‘æ›´æ–°")
        recent_files = self._get_recently_modified_files()
        summary.extend(self._format_recent_files_with_sessions(recent_files))
        
        # é¡¹ç›®çŠ¶æ€ï¼ˆé›†æˆæ‰‹åŠ¨çŠ¶æ€è®°å½•ï¼‰
        summary.append("")
        summary.append("## é¡¹ç›®ç®¡ç†çŠ¶æ€")
        project_status = self._get_project_status()
        summary.append(project_status)
        
        # æŠ€æœ¯çº¦æŸ
        summary.append("")
        summary.append("## æŠ€æœ¯çº¦æŸ")
        summary.append(self._get_technical_constraints())
        
        # å½“å‰å¼€å‘çŠ¶æ€
        summary.append("")
        summary.append("## å½“å‰å¼€å‘çŠ¶æ€")
        summary.append(self._get_development_status())
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„å­—ç¬¦ä¸²
        summary_md = "\n".join(summary)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        cache_file = self.ai_context_dir / "cache" / "latest-context.md"
        cache_file.parent.mkdir(exist_ok=True)
        with open(cache_file, 'w', encoding='utf-8') as f:
            f.write(summary_md)
        
        return summary_md
    
    def _read_project_config(self):
        """è¯»å–é¡¹ç›®é…ç½®ä¿¡æ¯"""
        config_file = self.ai_context_dir / CONFIG_FILE_NAME
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config.get('project', {})
            except (json.JSONDecodeError, FileNotFoundError):
                pass
        return {}
    
    def _get_core_features(self):
        """è·å–æ ¸å¿ƒåŠŸèƒ½ä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_FEATURES_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æ ¸å¿ƒåŠŸèƒ½", NO_FEATURES_MSG)
        except FileNotFoundError:
            return NO_FEATURES_MSG
    
    def _extract_section_content(self, content, section_header, default_message):
        """æå–æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        if section_header not in content:
            return default_message
        
        lines = content.split('\n')
        features = []
        in_section = False
        
        for line in lines:
            if line.startswith(section_header):
                in_section = True
            elif in_section and line.startswith("##"):
                break
            elif in_section and line.strip():
                features.append(line.strip())
        
        return '\n'.join(features[:5]) if features else default_message
    
    def _get_technical_constraints(self):
        """è·å–æŠ€æœ¯çº¦æŸä¿¡æ¯"""
        overview_file = self.ai_context_dir / "docs" / "project-overview.md"
        if not overview_file.exists():
            return NO_CONSTRAINTS_MSG
        
        try:
            with open(overview_file, 'r', encoding='utf-8') as f:
                content = f.read()
            return self._extract_section_content(content, "## æŠ€æœ¯çº¦æŸ", NO_CONSTRAINTS_MSG)
        except FileNotFoundError:
            return NO_CONSTRAINTS_MSG
    
    def _get_important_files(self):
        """è·å–é‡è¦æ–‡ä»¶åˆ—è¡¨"""
        important_files = []
        self._scan_directory(self.project_root, important_files)
        return "\n".join(important_files[:50]) if important_files else NO_FILES_MSG  # å¢åŠ åˆ°50ä¸ªæ–‡ä»¶
    
    def _scan_directory(self, path, important_files, prefix="", current_depth=0):
        """é€’å½’æ‰«æç›®å½•ç»“æ„ï¼ˆåŸºäºé…ç½®ï¼‰"""
        max_depth = self.scanning_config.get('max_depth', 3)
        if current_depth >= max_depth:
            return
        
        try:
            items = list(path.iterdir())
            dirs = [item for item in items if item.is_dir() and self._is_important_dir(item)]
            files = [item for item in items if item.is_file() and self._is_important_file(item)]
            
            # æ·»åŠ é‡è¦ç›®å½•
            for directory in sorted(dirs):
                try:
                    important_files.append(f"{prefix}- ğŸ“ {directory.name}/")
                    self._scan_directory(directory, important_files, prefix + "  ", current_depth + 1)
                except UnicodeError:
                    # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬ç‰ˆæœ¬
                    important_files.append(f"{prefix}- [DIR] {directory.name}/")
                    self._scan_directory(directory, important_files, prefix + "  ", current_depth + 1)
            
            # æ·»åŠ é‡è¦æ–‡ä»¶
            for file_path in sorted(files):
                try:
                    important_files.append(f"{prefix}- ğŸ“„ {file_path.name}")
                except UnicodeError:
                    # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬ç‰ˆæœ¬
                    important_files.append(f"{prefix}- [FILE] {file_path.name}")
                        
        except PermissionError:
            pass
        except Exception as e:
            # æ·»åŠ é€šç”¨å¼‚å¸¸å¤„ç†ä»¥è¯Šæ–­é—®é¢˜
            important_files.append(f"{prefix}- [ERROR] æ‰«æ {path.name} æ—¶å‡ºé”™: {e}")
    
    def _is_important_dir(self, directory):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦ç›®å½•ï¼ˆåŸºäºé…ç½®ï¼‰"""
        include_hidden = self.scanning_config.get('include_hidden_dirs', False)
        special_include = self.scanning_config.get('special_include_dirs', [])
        exclude_dirs = self.scanning_config.get('exclude_dirs', [])
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if directory.name in exclude_dirs:
            return False
        
        # æ£€æŸ¥ç‰¹æ®ŠåŒ…å«ç›®å½•
        if directory.name in special_include:
            return True
        
        # æ£€æŸ¥éšè—ç›®å½•
        if directory.name.startswith('.'):
            return include_hidden
        
        return True
    
    def _is_important_file(self, file_path):
        """åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦æ–‡ä»¶ï¼ˆåŸºäºé…ç½®ï¼‰"""
        important_extensions = self.scanning_config.get('important_extensions', [])
        
        # è·³è¿‡éšè—æ–‡ä»¶ï¼ˆé™¤éé…ç½®å…è®¸ï¼‰
        if file_path.name.startswith('.'):
            return False
            
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        return file_path.suffix.lower() in important_extensions
    
    def _get_recent_changes(self):
        """è·å–æœ€è¿‘å˜æ›´ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        changes = []
        
        try:
            # è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
            recent_files = self._get_recently_modified_files()
            if recent_files:
                changes.extend(self._format_recent_files(recent_files))
            
            # å°è¯•è·å–Gitå†å²
            git_history = self._get_git_history()
            if git_history:
                changes.append("\n## Gitæäº¤å†å²:")
                changes.extend(git_history)
            
            if not changes:
                changes.append("- æœªå‘ç°æœ€è¿‘æ›´æ”¹")
                
        except Exception as e:
            changes.append(f"- è·å–å˜æ›´ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return "\n".join(changes)
    
    def _get_recently_modified_files(self):
        """è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆåŸºäºé…ç½®ï¼‰"""
        recent_config = self._get_recent_files_config()
        days_threshold = recent_config.get('days_threshold', 7)
        max_depth = recent_config.get('max_depth', 3)
        cutoff_time = datetime.now().timestamp() - (days_threshold * 24 * 3600)
        
        recent_files = []
        self._collect_recent_files(self.project_root, recent_files, cutoff_time, max_depth)
        return sorted(recent_files, key=lambda x: x[1], reverse=True)
    
    def _get_recent_files_config(self):
        """è·å–æœ€è¿‘æ–‡ä»¶é…ç½®"""
        recent_config = self.scanning_config
        if 'recent_files' in self.scanning_config:
            config_file = self.ai_context_dir / CONFIG_FILE_NAME
            if config_file.exists():
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        full_config = json.load(f)
                        recent_config = full_config.get('recent_files', self.scanning_config)
                except (json.JSONDecodeError, FileNotFoundError, IOError):
                    pass
        return recent_config
    
    def _collect_recent_files(self, path, recent_files, cutoff_time, max_depth, current_depth=0):
        """é€’å½’æ”¶é›†æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶"""
        if current_depth >= max_depth:
            return
            
        try:
            for item in path.iterdir():
                if item.is_dir() and self._is_important_dir(item):
                    self._collect_recent_files(item, recent_files, cutoff_time, max_depth, current_depth + 1)
                elif item.is_file() and self._is_recent_file(item, cutoff_time):
                    rel_path = item.relative_to(self.project_root)
                    recent_files.append((str(rel_path), item.stat().st_mtime))
        except PermissionError:
            pass
    
    def _is_recent_file(self, item, cutoff_time):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºæœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶"""
        if item.stat().st_mtime <= cutoff_time:
            return False
        return self._is_important_file(item) or not item.name.startswith('.')
    
    def _format_recent_files(self, recent_files):
        """æ ¼å¼åŒ–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨"""
        changes = ["## æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶:"]
        for file_path, mtime in recent_files[:10]:
            mod_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M")
            changes.append(f"- {file_path} ({mod_time})")
        return changes
    
    def _get_git_history(self):
        """è·å–Gitæäº¤å†å²"""
        try:
            import subprocess
            result = subprocess.run(
                ["git", "log", "--oneline", "-5"],
                capture_output=True, text=True, cwd=self.project_root
            )
            if result.returncode == 0 and result.stdout.strip():
                return [f"- {line}" for line in result.stdout.strip().split('\n')]
        except Exception:
            pass
        return None
    
    def _get_development_status(self):
        """è·å–å½“å‰å¼€å‘çŠ¶æ€"""
        detector = ProjectDetector(str(self.project_root))
        proj_type, _ = detector.detect_project_type()
        
        status_info = []
        
        if proj_type == "context-management-system":
            status_info.extend(self._check_context_system_status())
        else:
            status_info.extend(self._check_traditional_project_status())
        
        # é€šç”¨æ–‡æ¡£æ£€æŸ¥
        self._check_documentation_status(status_info)
        
        return "\n".join([f"- {info}" for info in status_info]) or "- é¡¹ç›®åˆšå¼€å§‹"
    
    def _check_context_system_status(self):
        """æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»ŸçŠ¶æ€"""
        status_info = []
        
        # æ£€æŸ¥æ ¸å¿ƒå·¥å…·è„šæœ¬
        status_info.append(self._check_tools_status())
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        status_info.append(self._check_config_status())
        
        # æ£€æŸ¥VS Codeé›†æˆ
        status_info.append(self._check_vscode_integration())
        
        # æ£€æŸ¥æ¨¡æ¿ç³»ç»Ÿ
        status_info.append(self._check_templates_status())
        
        # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
        status_info.append(self._check_cache_status())
        
        # æ£€æŸ¥å¿«é€Ÿéƒ¨ç½²è„šæœ¬
        status_info.append(self._check_deploy_script_status())
        
        return status_info
    
    def _check_tools_status(self):
        """æ£€æŸ¥å·¥å…·è„šæœ¬çŠ¶æ€"""
        tools_dir = self.project_root / AI_CONTEXT_DIR / "tools"
        if not tools_dir.exists():
            return "â³ æ ¸å¿ƒå·¥å…·è„šæœ¬æœªå¼€å§‹"
        
        tool_files = [f for f in tools_dir.glob("*.py") if f.name != "__init__.py"]
        if tool_files:
            return f"âœ… æ ¸å¿ƒå·¥å…·è„šæœ¬ ({len(tool_files)} ä¸ªå·¥å…·)"
        else:
            return "â³ æ ¸å¿ƒå·¥å…·è„šæœ¬æœªå®Œæˆ"
    
    def _check_config_status(self):
        """æ£€æŸ¥é…ç½®æ–‡ä»¶çŠ¶æ€"""
        config_file = self.project_root / AI_CONTEXT_DIR / CONFIG_FILE_NAME
        return "âœ… é…ç½®ç³»ç»Ÿå·²å®Œæˆ" if config_file.exists() else "â³ é…ç½®ç³»ç»Ÿæœªå®Œæˆ"
    
    def _check_vscode_integration(self):
        """æ£€æŸ¥VS Codeé›†æˆçŠ¶æ€"""
        vscode_dir = self.project_root / ".vscode"
        if not vscode_dir.exists():
            return "â³ VS Codeé›†æˆæœªå¼€å§‹"
        
        tasks_file = vscode_dir / "tasks.json"
        return "âœ… VS Codeä»»åŠ¡é›†æˆå®Œæˆ" if tasks_file.exists() else "â³ VS Codeä»»åŠ¡é›†æˆæœªå®Œæˆ"
    
    def _check_templates_status(self):
        """æ£€æŸ¥æ¨¡æ¿ç³»ç»ŸçŠ¶æ€"""
        templates_dir = self.project_root / AI_CONTEXT_DIR / "templates"
        if templates_dir.exists() and list(templates_dir.glob("*.md")):
            return "âœ… æ¨¡æ¿ç³»ç»Ÿå·²å®Œæˆ"
        else:
            return "â³ æ¨¡æ¿ç³»ç»Ÿæœªå®Œæˆ"
    
    def _check_cache_status(self):
        """æ£€æŸ¥ç¼“å­˜ç³»ç»ŸçŠ¶æ€"""
        cache_dir = self.project_root / AI_CONTEXT_DIR / "cache"
        if cache_dir.exists() and list(cache_dir.glob("*.md")):
            return "âœ… ç¼“å­˜ç³»ç»Ÿæ­£å¸¸è¿è¡Œ"
        else:
            return "â³ ç¼“å­˜ç³»ç»Ÿæœªå¯ç”¨"
    
    def _check_deploy_script_status(self):
        """æ£€æŸ¥éƒ¨ç½²è„šæœ¬çŠ¶æ€"""
        deploy_script = self.project_root / "deploy-ai-context.py"
        return "âœ… å¿«é€Ÿéƒ¨ç½²è„šæœ¬å®Œæˆ" if deploy_script.exists() else "â³ å¿«é€Ÿéƒ¨ç½²è„šæœ¬æœªå®Œæˆ"
    
    def _check_traditional_project_status(self):
        """æ£€æŸ¥ä¼ ç»Ÿé¡¹ç›®çŠ¶æ€"""
        status_info = []
        
        # æ£€æŸ¥æ•°æ®åº“
        db_files = list(self.project_root.glob("**/*.db"))
        if db_files:
            status_info.append(f"âœ… æ•°æ®åº“å·²åˆ›å»º ({len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶)")
        else:
            status_info.append("â³ æ•°æ®åº“æœªåˆ›å»º")
        
        # æ£€æŸ¥åç«¯ä»£ç 
        backend_dir = self.project_root / "backend"
        if backend_dir.exists():
            backend_files = list(backend_dir.glob("**/*.py"))
            if backend_files:
                status_info.append(f"ğŸ”§ åç«¯å¼€å‘ä¸­ ({len(backend_files)} ä¸ªPythonæ–‡ä»¶)")
            else:
                status_info.append("â³ åç«¯ä»£ç æœªå¼€å§‹")
        else:
            status_info.append("â³ åç«¯ä»£ç æœªå¼€å§‹")
        
        # æ£€æŸ¥å‰ç«¯ä»£ç 
        frontend_status = self._check_frontend_status()
        status_info.append(frontend_status)
        
        # æ£€æŸ¥æµ‹è¯•ä»£ç 
        test_status = self._check_test_status()
        status_info.append(test_status)
        
        return status_info
    
    def _check_frontend_status(self):
        """æ£€æŸ¥å‰ç«¯ä»£ç çŠ¶æ€"""
        frontend_dir = self.project_root / "frontend"
        if not frontend_dir.exists():
            return "â³ å‰ç«¯ä»£ç æœªå¼€å§‹"
        
        frontend_files = []
        frontend_files.extend(list(frontend_dir.glob("**/*.html")))
        frontend_files.extend(list(frontend_dir.glob("**/*.js")))
        frontend_files.extend(list(frontend_dir.glob("**/*.css")))
        
        if frontend_files:
            return f"ğŸ¨ å‰ç«¯å¼€å‘ä¸­ ({len(frontend_files)} ä¸ªå‰ç«¯æ–‡ä»¶)"
        else:
            return "â³ å‰ç«¯ä»£ç æœªå¼€å§‹"
    
    def _check_test_status(self):
        """æ£€æŸ¥æµ‹è¯•ä»£ç çŠ¶æ€"""
        tests_dir = self.project_root / "tests"
        if tests_dir.exists():
            test_files = list(tests_dir.glob("**/*.py"))
            if test_files:
                return f"ğŸ§ª æµ‹è¯•ä»£ç  ({len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶)"
        return "â³ æµ‹è¯•ä»£ç æœªç¼–å†™"
    
    def _check_documentation_status(self, status_info):
        """æ£€æŸ¥æ–‡æ¡£çŠ¶æ€"""
        doc_files = list(self.project_root.glob("**/*.md"))
        doc_count = len([f for f in doc_files if AI_CONTEXT_DIR not in str(f)])
        if doc_count > 0:
            status_info.append(f"ğŸ“š é¡¹ç›®æ–‡æ¡£ ({doc_count} ä¸ªæ–‡æ¡£æ–‡ä»¶)")
    
    def _get_project_status(self):
        """è¯»å–æœ€æ–°çš„é¡¹ç›®çŠ¶æ€ä¿¡æ¯"""
        status_file = self.project_root / AI_CONTEXT_DIR / 'status' / 'latest-status.md'
        
        if not status_file.exists():
            return "æš‚æ— é¡¹ç›®çŠ¶æ€è®°å½•"
            
        try:
            with open(status_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å…³é”®ä¿¡æ¯
            lines = content.split('\n')
            status_summary = []
            current_section = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('## å®Œæˆçš„å·¥ä½œ'):
                    current_section = 'completed'
                elif line.startswith('## è¿›è¡Œä¸­çš„ä»»åŠ¡'):
                    current_section = 'ongoing'
                elif line.startswith('## å¾…å¤„ç†é—®é¢˜'):
                    current_section = 'issues'
                elif line.startswith('## ä¸‹ä¸€æ­¥è®¡åˆ’'):
                    current_section = 'next'
                elif line.startswith('## é‡è¦è¯´æ˜'):
                    current_section = 'notes'
                elif line.startswith('- [x]') and current_section == 'completed':
                    status_summary.append(f"âœ… {line[6:].strip()}")
                elif line.startswith('- [ ]') and current_section == 'ongoing':
                    status_summary.append(f"ğŸ”„ {line[6:].strip()}")
                elif line.startswith('1.') and current_section == 'issues':
                    status_summary.append(f"â— {line[3:].strip()}")
                    
            return '\n'.join(status_summary[:8])  # é™åˆ¶æ˜¾ç¤ºæ¡ç›®
            
        except Exception as e:
            return f"è¯»å–é¡¹ç›®çŠ¶æ€æ—¶å‡ºé”™: {e}"
    
    def _get_session_context(self):
        """è·å–ä¼šè¯ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            # å¯¼å…¥ä¼šè¯ç®¡ç†å™¨
            session_manager_path = self.ai_context_dir / "tools" / "session-manager.py"
            if not session_manager_path.exists():
                return None
            
            # åŠ¨æ€å¯¼å…¥
            import importlib.util
            spec = importlib.util.spec_from_file_location("session_manager", session_manager_path)
            
            if spec is None or spec.loader is None:
                print(f"æ— æ³•ä»è·¯å¾„åŠ è½½æ¨¡å—: {session_manager_path}")
                return None
                
            session_manager_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(session_manager_module)
            
            # åˆ›å»ºä¼šè¯ç®¡ç†å™¨å®ä¾‹
            manager = session_manager_module.SessionManager(str(self.project_root))
            
            # è·å–æœ€è¿‘çš„ä¼šè¯
            recent_sessions = manager.get_recent_sessions(days=7)
            
            return recent_sessions
        except Exception:
            return None
    
    def _format_recent_files_with_sessions(self, recent_files):
        """æ ¼å¼åŒ–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼ŒåŒ…å«ä¼šè¯ä¿¡æ¯"""
        session_context = self._get_session_context()
        
        if not session_context:
            return self._format_recent_files(recent_files)
        
        changes = ["## æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶:"]
        sessions_by_time, unassigned_files = self._group_files_by_session(recent_files[:10], session_context)
        
        # è¾“å‡ºæŒ‰ä¼šè¯åˆ†ç»„çš„æ–‡ä»¶
        self._append_session_files(changes, sessions_by_time)
        
        # è¾“å‡ºæœªåˆ†é…çš„æ–‡ä»¶
        self._append_unassigned_files(changes, unassigned_files)
        
        return changes
    
    def _group_files_by_session(self, recent_files, session_context):
        """æŒ‰ä¼šè¯åˆ†ç»„æ–‡ä»¶"""
        sessions_by_time = {}
        unassigned_files = []
        
        for file_path, mtime in recent_files:
            file_time = datetime.fromtimestamp(mtime)
            session_key = self._find_file_session(file_time, session_context)
            
            if session_key:
                session = next(s for s in session_context if s["session_id"] == session_key)
                if session_key not in sessions_by_time:
                    sessions_by_time[session_key] = {"session": session, "files": []}
                sessions_by_time[session_key]["files"].append((file_path, mtime))
            else:
                unassigned_files.append((file_path, mtime))
        
        return sessions_by_time, unassigned_files
    
    def _find_file_session(self, file_time, session_context):
        """æŸ¥æ‰¾æ–‡ä»¶æ‰€å±çš„ä¼šè¯"""
        for session in session_context:
            start_time = datetime.fromisoformat(session["start_time"])
            end_time = datetime.fromisoformat(session["end_time"]) if session.get("end_time") else datetime.now()
            
            if start_time <= file_time <= end_time:
                return session["session_id"]
        return None
    
    def _append_session_files(self, changes, sessions_by_time):
        """æ·»åŠ ä¼šè¯æ–‡ä»¶åˆ°è¾“å‡º"""
        for session_data in sessions_by_time.values():
            session = session_data["session"]
            files = session_data["files"]
            
            time_range = self._format_session_time_range(session)
            status_icon = "ğŸŸ¢" if session["status"] == "active" else "âœ…"
            changes.append(f"{status_icon} [ä¼šè¯] {session['title']} ({time_range})")
            
            if session.get("description"):
                changes.append(f"   ğŸ“ {session['description']}")
            
            for file_path, mtime in sorted(files, key=lambda x: x[1], reverse=True):
                mod_time = datetime.fromtimestamp(mtime).strftime("%H:%M")
                changes.append(f"   - {file_path} ({mod_time})")
            
            changes.append("")
    
    def _format_session_time_range(self, session):
        """æ ¼å¼åŒ–ä¼šè¯æ—¶é—´èŒƒå›´"""
        start_time = datetime.fromisoformat(session["start_time"]).strftime("%H:%M")
        if session.get("end_time"):
            end_time = datetime.fromisoformat(session["end_time"]).strftime("%H:%M")
            return f"{start_time}-{end_time}"
        else:
            return f"{start_time}-(è¿›è¡Œä¸­)"
    
    def _append_unassigned_files(self, changes, unassigned_files):
        """æ·»åŠ æœªåˆ†é…çš„æ–‡ä»¶åˆ°è¾“å‡º"""
        if unassigned_files:
            changes.append("ğŸ“„ å…¶ä»–ä¿®æ”¹:")
            for file_path, mtime in unassigned_files:
                mod_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M")
                changes.append(f"- {file_path} ({mod_time})")

if __name__ == "__main__":
    generator = ContextGenerator(".")
    summary = generator.generate_context_summary()
    
    # å¤„ç† Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
    try:
        print(summary)
    except UnicodeEncodeError:
        # å¦‚æœæœ‰ç¼–ç é—®é¢˜ï¼Œæ›¿æ¢æ‰€æœ‰å¯èƒ½æœ‰é—®é¢˜çš„å­—ç¬¦
        safe_summary = summary.replace('ğŸ“', '[DIR]').replace('ğŸ“„', '[FILE]')
        safe_summary = safe_summary.replace('âœ…', '[OK]').replace('ğŸŸ¢', '[ACTIVE]')
        safe_summary = safe_summary.replace('ğŸ“', '[DESC]').replace('â±ï¸', '[TIME]')
        safe_summary = safe_summary.replace('ğŸ“‹', '[LIST]').replace('ğŸ·ï¸', '[TAG]')
        try:
            print(safe_summary)
        except UnicodeEncodeError:
            # å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶
            output_file = "context-output.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(summary)
            print(f"ä¸Šä¸‹æ–‡å·²è¾“å‡ºåˆ°æ–‡ä»¶: {output_file}")
